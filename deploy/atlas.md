# Apache-Atlasç¼–è¯‘å®‰è£…åŠæ•´åˆHiveã€HBase

å‚è€ƒé“¾æ¥ï¼šhttp://atlas.apache.org

(ç¼–è¯‘ä¸å®‰è£…å‚è€ƒ)

https://blog.csdn.net/xiangwang2206/article/details/111503412

https://blog.csdn.net/xiangwang2206/article/details/112001194?utm_medium=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-OPENSEARCH-1.control

(æ•´åˆå„ä¸ªç»„ä»¶å‚è€ƒ)

https://www.cnblogs.com/shenyuelan/p/14085496.html

(ç†è§£atlaså·¥ä½œåŸç†çš„å¤§æ¦‚)

https://blog.csdn.net/tomalun/article/details/105100307

## ä¸€ã€ç¯å¢ƒå‡†å¤‡

æ³¨ï¼šå¦‚æœè¦ç‹¬ç«‹éƒ¨ç½²atlaså’Œå…¶ä»–ç»„ä»¶çš„è¯ï¼Œä»¥ä¸‹æ˜¯ç¯å¢ƒå¿…å¤‡ç»„ä»¶ï¼Œå¦åˆ™é€‰æ‹©éƒ¨ç½²å¸¦æœ‰å†…åµŒç»„ä»¶çš„atlasçš„è¯ï¼Œåªè¦jdk1.8xåŠä»¥ä¸Šå°±è¡Œã€‚

### 1. ç»„ä»¶ç‰ˆæœ¬
|ç»„ä»¶|ç‰ˆæœ¬|
|:--|:--|
|os|Linux 3.10.0-1127.el7.x86_64|
|java|1.8.0_261|
|zookeeper|3.6.2|
|kafka|2.13-2.7.0(ç‰ˆæœ¬åé«˜)|
|hadoop|2.6.0(ç‰ˆæœ¬åä½)|
|hbase|2.2.6|
|solr|8.6.3|
|hive|2.0.1(ç‰ˆæœ¬åä½)|
|atlas|2.1.0|

### 2.è§’è‰²åˆ†é…
|ç»„ä»¶|30.23.5.180(master)|30.23.4.69(slave-01)|30.23.5.206(slave-02)|30.23.4.117(slave-03)|30.23.5.142(slave-04)|30.23.4.95(slave-05)|30.23.4.187(slave-06)|
|:--|:--|:--|:--|:--|:--|:--|:--|
|zookeeper|&radic;-Leader|&radic;-Follower|&radic;-Follower|--|--|--|--|
|kafka|&radic;-9092|&radic;|&radic;|--|--|--|--|
|NameNode|&radic;-50070|--|--|--|--|--|--|
|SecondaryNameNode|&radic;-50090|--|--|--|--|--|--|
|MR JobHistory Server|&radic;|&radic;|&radic;|&radic;|&radic;|&radic;|&radic;|
|DataNode|--|&radic;|&radic;|&radic;|&radic;|&radic;|&radic;|
|ResourceManager|&radic;|--|--|--|--|--|--|
|NodeManager|--|&radic;|&radic;|&radic;|&radic;|&radic;|&radic;|
|hbase|&radic;-HMaster|--|--|--|&radic;-HMaster,HRegionServer|&radic;-HRegionServer|&radic;-HRegionServer|
|solr|&radic;|&radic;|&radic;|--|--|--|--|
|hive|&radic;|--|--|--|--|--|--|
|MySQL|&radic;|--|--|--|--|--|--|
|atlas|&radic;|--|--|--|--|--|--|

## äºŒã€ç¼–è¯‘
ç”±äºAtlaséœ€è¦ä¸åŒç»„ä»¶é…ç½®å¥½äº†æ‰èƒ½æ­£å¸¸å¯åŠ¨ï¼Œå„ç»„ä»¶ç‰ˆæœ¬ä¸åŒï¼Œæ‰€éœ€è¦çš„å®‰è£…åŒ…ä¸åŒï¼Œæ‰€ä»¥å®˜ç½‘ä¸Šæ²¡æœ‰æä¾›ç¼–è¯‘å¥½çš„äºŒè¿›åˆ¶åŒ…ï¼Œåªæœ‰æºç åŒ…ğŸ˜­ï¼Œå¼€å§‹ç¼–è¯‘å‰ï¼Œæ£€æŸ¥ç¯å¢ƒçš„mavenï¼Œjdkç‰ˆæœ¬è¦åˆ†åˆ«åœ¨Maven3.Xï¼Œjdk1.8xåŠä»¥ä¸Šï¼Œç³»ç»Ÿæœ€å¥½é»˜è®¤python2.7ä»¥ä¾¿ä¹‹åå¯åŠ¨atlasçš„pythonè„šæœ¬ã€‚

å‰å¾€å®˜ç½‘ï¼Œä¸‹è½½atlas 2.1.0ç‰ˆæœ¬ï¼šhttps://atlas.apache.org/#/Downloads

### 1. ä¿®æ”¹éƒ¨åˆ†é…ç½®æ–‡ä»¶

ç¼–è¯‘ä¸‹è½½å‰ä¿®æ”¹mavené•œåƒï¼Œäº²æµ‹é˜¿é‡Œçš„é•œåƒæœ€å¥½ç”¨ï¼Œä¿®æ”¹apache-maven-3.6.x/conf/settings.xmlä¸­<mirros>éƒ¨åˆ†å¦‚ä¸‹:

```
<mirror>
    <id>alimaven</id>
    <name>aliyun maven</name>
    <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
    <mirrorOf>central</mirrorOf>
</mirror>
```
æŠŠä¿®æ”¹å¥½çš„settings.xmlæ‹·è´åˆ°~/.m2/

```
cp .../apache-maven-3.6x/conf/settings.xml ~/.m2/
```

ä¹‹åå›åˆ°atlaså‹ç¼©åŒ…æ‰€åœ¨ç›®å½•ï¼š

```
tar xvzf apache-atlas-2.1.0-sources.tar.gz
```

ä¿®æ”¹atlasæºç å·¥ç¨‹ä¸­çš„pom.xmlï¼šå°†hbase, zookeeper, hiveç­‰ä¾èµ–ç‰ˆæœ¬ä¿®æ”¹æˆè‡ªå·±ç¯å¢ƒä¸­ä¸€è‡´çš„æˆ–å…¼å®¹ç‰ˆæœ¬:

```
<hadoop.version>3.1.1</hadoop.version>
<hbase.version>2.2.6</hbase.version>
<solr.version>8.6.3</solr.version>
<hive.version>3.1.0</hive.version>
<kafka.version>2.2.1</kafka.version>
<kafka.scala.binary.version>2.11</kafka.scala.binary.version>
<calcite.version>1.16.0</calcite.version>
<zookeeper.version>3.6.2</zookeeper.version>
```

æ³¨ï¼šè‡ªå·±ç¯å¢ƒä¸­hiveç‰ˆæœ¬ä¸€èˆ¬æ˜¯2.xä½†è¿™é‡Œä¿æŒå…¶é»˜è®¤çš„3.1.0ï¼Œç¯å¢ƒä¸­hadoopç‰ˆæœ¬åä½ç¼–è¯‘ä¸‹è½½å®¹æ˜“å¤±è´¥ï¼Œæ‰€ä»¥ä¿æŒå…¶é»˜è®¤ï¼Œè€Œç¯å¢ƒä¸­kafkaåŠå…¶æ‰€ç¼–å†™çš„scalaç‰ˆæœ¬åé«˜ï¼Œæ‰€ä»¥ä¿æŒå…¶é»˜è®¤

### 2. æ‰§è¡Œmavenç¼–è¯‘

```
cd apache-atlas-sources-2.1.0/
export MAVEN_OPTS="-Xms2g -Xmx2g"
mvn clean -DskipTests install
```
Atlaså¯ä»¥ä½¿ç”¨å†…åµŒçš„hbase-solrä½œä¸ºåº•å±‚ç´¢å¼•å‚¨å­˜å’Œæœç´¢ç»„ä»¶ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¤–ç½®çš„hbaseå’Œsolrï¼Œé€‰æ‹©å…¶ä¸­ä¹‹ä¸€çš„æ–¹å¼å°±è¡Œã€‚

#### a. æ‰“åŒ…å†…åµŒç»„ä»¶çš„è¯ï¼Œæœ€å¥½å…ˆä¿®æ”¹distroæ–‡ä»¶å¤¹ä¸­hbaseå’Œsolrå‹ç¼©åŒ…çš„ä¸‹è½½è·¯å¾„ä¸º:

```
<hbase.tar>http://mirrors.tuna.tsinghua.edu.cn/apache/hbase/${hbase.version}/hbase-${hbase.version}-bin.tar.gz</hbase.tar>

<solr.tar>http://mirrors.tuna.tsinghua.edu.cn/apache/lucene/solr/${solr.version}/solr-${solr.version}.tgz</solr.tar>
```

```
mvn clean -DskipTests package -Pdist,embedded-hbase-solr
```

#### b. å¦‚æœä¸å†…ç½®çš„è¯:

```
mvn clean -DskipTests package -Pdist
```

#### c. ä»¥debugæ¨¡å¼ç¼–è¯‘ä¸‹è½½ï¼š

```
mvn clean -DskipTests package -Pdist -X
```

ç¼–è¯‘æ‰“åŒ…æ—¶é•¿æ¯”è¾ƒæ…¢ï¼Œä¸€èˆ¬è¦2ä¸ªå°æ—¶ï¼Œè¿™ä¸ªæ—¶å€™å–æ¯å’–å•¡ï¼Œçœ‹äº›æ–‡ç« ï¼Œä¸€ä¼šå„¿å°±è¿‡å»äº†ã€‚é‡åˆ°çš„é—®é¢˜æ— éæ˜¯ç½‘ç»œä¼ è¾“ï¼Œnodeä»£ç†ç­‰é—®é¢˜ï¼Œå¯ä»¥ä¸Šç½‘æŸ¥æ‰¾å¤±è´¥æ–‡ä»¶æ‰€å¯¹åº”çš„jaråŒ…ä»¥åŠpomæ–‡ä»¶ä¸‹è½½æ”¾å…¥æœ¬åœ°mavenä»“åº“ç›¸åº”çš„è·¯å¾„ä¸­/root/.m2/repository/...

æœ¬äººæ¯”è¾ƒå¹¸è¿ï¼Œç¬¬ä¸€æ¬¡ç¼–è¯‘é€‰æ‹©å†…åµŒhbaseå’ŒsolråªæŠ¥äº†ä¸€ä¸ªæœ‰å…³æ–‡ä»¶â€œToo many files with unapproved licenseâ€çš„é”™ï¼Œåˆ é™¤å¯¹åº”æŠ¥é”™è·¯å¾„å¤šä½™çš„æ–‡ä»¶ï¼Œé‡æ–°åœ¨å®˜ç½‘ä¸Šä¸‹è½½å¯¹åº”çš„å‹ç¼©åŒ…æ”¾è¿›apache-atlas-sources-2.1.0ä¸­å¯¹åº”è·¯å¾„å†ç»§ç»­ä¹‹å‰çš„ç¼–è¯‘å°±å¥½

```
mvn clean -DskipTests package -Pdist,embedded-hbase-solr -rf :æŠ¥é”™çš„åŒ…å
```

ç¼–è¯‘ä¸‹è½½æˆåŠŸï¼Œå…ˆğŸ»åº†ç¥ï¼Œç„¶åæŸ¥çœ‹apache-sources-2.1.0/distro/targetä¸‹ï¼Œä½ å¯ä»¥çœ‹åˆ°å„ç§å‹ç¼©åŒ…ï¼ŒåŒ…æ‹¬äºŒè¿›åˆ¶å‹ç¼©åŒ…ï¼Œç”¨æ¥ç›‘å¬å„ä¸ªç»„ä»¶çš„hookå‹ç¼©åŒ…ä»¥åŠå•çº¯atlasçš„serverå‹ç¼©åŒ…ã€‚

```
distro/target/apache-atlas-{project.version}-bin.tar.gz
distro/target/apache-atlas-{project.version}-hbase-hook.tar.gz
distro/target/apache-atlas-{project.version}-hive-hook.gz
distro/target/apache-atlas-{project.version}-kafka-hook.gz
distro/target/apache-atlas-{project.version}-sources.tar.gz
distro/target/apache-atlas-{project.version}-sqoop-hook.tar.gz
distro/target/apache-atlas-{project.version}-storm-hook.tar.gz
```

å»å…¶ç³Ÿç²•ï¼Œå–å…¶ç²¾åï¼Œåªè¦å°†apache-atlas-2.1.0-bin.tar.gzè§£å‹åˆ°æœåŠ¡å™¨ä½ ä¸“é—¨å­˜æ”¾serveræˆ–è€…dataä¹‹ç±»çš„æ–‡ä»¶å¤¹ä¸­ï¼Œæºç åŒ…å…¶ä»–çš„ç”¨ä¸åˆ°ã€‚æ‰€ä»¥å½“æ—¶ç¼–è¯‘ï¼Œæœ¬äººåœ¨æœ¬åœ°ç”µè„‘ä¸Šè¿›è¡Œï¼Œç„¶åå¾—åˆ°äºŒè¿›åˆ¶å‹ç¼©åŒ…æ”¾åˆ°æœåŠ¡å™¨ä¸Šï¼Œè¿›è¡Œä¸‹ä¸€æ­¥ã€‚

## ä¸‰ã€å®‰è£…

åˆ°ç¼–è¯‘å¥½çš„å·¥ç¨‹åŒ…çš„è·¯å¾„ä¸‹apache-atlas-sources-2.1.0/distro/targetï¼Œå°†ç”Ÿæˆå¥½çš„å®‰è£…åŒ…apache-atlas-2.1.0-bin.tar.gzæ‹·è´åˆ°ç›®æ ‡è·¯å¾„ä¸‹ï¼Œè§£å‹å¹¶ä¸”é‡å‘½åï¼š

```
tar zxvf apache-atlas-2.1.0-bin.tar.gz
mv apache-atlas-2.1.0 atlas-2.1.0
```

### (a) å¦‚æœå½“åˆé€‰æ‹©å†…åµŒç¼–è¯‘ä¸‹è½½çš„è¯ï¼Œåªè¦ç¡®ä¿ç¯å¢ƒä¸­å·²ç»é…ç½®å¥½JAVA_HOMEçš„ç¯å¢ƒå˜é‡ï¼Œå¯ä»¥ç›´æ¥å¯åŠ¨atlasï¼Œå¹¶åˆ°æ­¤ä¸ºæ­¢ï¼š

```
cd /data/servers/atlas-2.1.0
bin/atlas_start.py
```

### (b) å¦‚æœè¦é›†æˆå·²ç»æœ‰çš„ç»„ä»¶ï¼š

#### 1. ä¿®æ”¹é…ç½®æ–‡ä»¶atlas-env.shï¼š

```
vim /data/servers/atlas-2.1.0/conf/atlas-env.sh
```

atlas-env.shä¸­ä¿®æ”¹ä¸‹é¢å‡ é¡¹ï¼š

```
export JAVA_HOME=/usr/local/java/jdk1.8.0_261
export MANAGE_LOCAL_HBASE=false # ä¸å¯åŠ¨å†…åµŒç»„ä»¶
export MANAGE_LOCAL_SOLR=false
# ä¿®æ”¹Hbaseé…ç½®æ–‡ä»¶è·¯å¾„
export HBASE_CONF_DIR=/data/servers/hbase-2.2.6/conf
```
#### 2. ç„¶åæ˜¯é…ç½®çš„é‡ç‚¹ä»¥åŠéš¾ç‚¹ï¼Œä¿®æ”¹atlas-application.propertiesï¼š

```
vim /data/servers/atlas-2.1.0/conf/atlas-application.properties
```

atlas-application.propertiesä¸­ä¿®æ”¹hbaseï¼Œsolrï¼Œkafkaçš„é…ç½®ï¼Œå¹¶å¢åŠ æœ‰å…³hiveå’Œhbaseçš„hookçš„ç›¸å…³é…ç½®ï¼š

```
#Hbase
#for distributed mode, specify zookeeper quorum here
atlas.graph.storage.hostname=30.23.4.69:2181,30.23.5.206:2181,30.23.5.180:2181

#Solr
#Solr cloud mode properties
atlas.graph.index.search.solr.mode=cloud
atlas.graph.index.search.solr.zookeeper-url=30.23.4.69:2181,30.23.5.206:2181,30.23.5.180:2181/solr
atlas.graph.index.search.solr.zookeeper-connect-timeout=60000
atlas.graph.index.search.solr.zookeeper-session-timeout=60000
atlas.graph.index.search.solr.wait-searcher=true

#Notification Configs
atlas.notification.embedded=false
atlas.kafka.zookeeper.connect=30.23.4.69:2181,30.23.5.206:2181,30.23.5.180:2181/kafka
atlas.kafka.bootstrap.servers=30.23.4.69:9092,30.23.5.206:9092,30.23.5.180:9092
atlas.kafka.zookeeper.session.timeout.ms=60000
atlas.kafka.zookeeper.connection.timeout.ms=30000
atlas.kafka.enable.auto.commit=true

##### Server Properties #####
atlas.rest.address=http://localhost:21000

atlas.hook.hive.synchronous=false
atlas.hook.hive.numRetries=3
atlas.hook.hive.queueSize=10000

atlas.hook.hbase.synchronous=false
atlas.hook.hbase.numRetries=3
atlas.hook.hbase.queueSize=10000

atlas.cluster.name=primary
```

ç„¶åå¯åŠ¨atlasï¼Œå¹¶å¯å¼•å…¥ä¸€äº›exampleæ•°æ®ï¼š

```
cd /data/servers/atlas-2.1.0
bin/atlas_start.py
bin/quick_start.py
```

## å››ã€æ•´åˆHBaseã€Hive

è¿™æ˜¯æ•´ä¸ªè¿‡ç¨‹ä¸­æœ€æ¶ˆç£¨ä¸€ä¸ªäººçƒ­æƒ…çš„æ—¶å€™ï¼Œè¯¸å›ä¸€è·¯ç¥ˆç¥·å§


### 1.æ•´åˆHBase

Atlasåœ¨HBase masteræ³¨å†Œä¸€ä¸ªé’©å­ï¼Œå½“æ£€æµ‹åˆ°HBaseä¸­namespaces/tables/column-familieså‘ç”Ÿå˜åŒ–æ—¶ï¼Œatlaså®‰æ’çš„è¿™ä¸ªé’©å­ä¼šé€šè¿‡kafkaé€šçŸ¥æ¥æ›´æ–°è¿™äº›å‚¨å­˜åœ¨atlasçš„å…ƒæ•°æ®ã€‚

#### 1.1 ä¿®æ”¹$HBASE_HOME/confé‡Œçš„hbase-site.xmlé…ç½®

```
vim /data/servers/hbase-2.2.6/conf/hbase-site.xml
```

åœ¨åŸå…ˆçš„hbase-site.xmlæ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ï¼š

```
<property>
  <name>hbase.coprocessor.master.classes</name>
  <value>org.apache.atlas.hbase.hook.HBaseAtlasCoprocessor</value>
</property>
```

#### 1.2 åœ¨$HBASE_HOME/libä¸­æ·»åŠ æ¥è‡ªhbase-hookçš„è½¯é“¾æ¥

```
ln -s /data/servers/atlas-2.1.0/hook/hbase/* $HBASE_HOME/lib/
```

#### 1.3 æ·»åŠ atlas-2.1.0/confä¸­çš„atlas-application.propertiesåˆ°$HBASE_HOME/confä¸­

atlas-application.propertiesä¸­çš„å¦‚ä¸‹å†…å®¹æ˜¯ç”¨æ¥æ§åˆ¶é’©å­çš„çº¿ç¨‹æ± ä»¥åŠKafkaé€šçŸ¥é…ç½®ï¼š

```
atlas.hook.hbase.synchronous=false # whether to run the hook synchronously. false recommended to avoid delays in HBase operations. Default: false
atlas.hook.hbase.numRetries=3      # number of retries for notification failure. Default: 3
atlas.hook.hbase.queueSize=10000   # queue size for the threadpool. Default: 10000
atlas.cluster.name=primary # clusterName to use in qualifiedName of entities. Default: primary
atlas.kafka.zookeeper.connect=30.23.4.69:2181,30.23.5.206:2181,30.23.5.180:2181/kafka
atlas.kafka.zookeeper.connection.timeout.ms=30000
atlas.kafka.zookeeper.session.timeout.ms=60000
atlas.kafka.zookeeper.sync.time.ms=20
```
#### 1.4 å¯¼å…¥åŸæœ‰HBaseæ•°æ®

```
cd /data/servers/atlas-2.1.0
hook-bin/import-hbase.sh
```

é™¤äº†ä¸Šè¿°å…¨å¯¼å…¥ä¹‹å¤–è¿˜å¯ä»¥é€‰æ‹©å¯¼å…¥ç‰¹å®šçš„è¡¨æ ¼æˆ–è€…åœ¨ç‰¹å®šnamespceçš„è¡¨æ ¼ï¼Œç”¨æ³•å¦‚ä¸‹ï¼š

```
Usage 1: <atlas package>/hook-bin/import-hbase.sh
Usage 2: <atlas package>/hook-bin/import-hbase.sh [-n <namespace regex> OR --namespace <namespace regex>] [-t <table regex> OR --table <table regex>]
Usage 3: <atlas package>/hook-bin/import-hbase.sh [-f <filename>]
           File Format:
             namespace1:tbl1
             namespace1:tbl2
             namespace2:tbl1
```

ä¸‹é¢å¼€å§‹è¸©å‘è®°å½•ï¼š

```
...
Caused by: org.apache.commons.configuration.ConversionException: 'atlas.graph.index.search.solr.wait-searcher' doesn't map to a List object: true, a java.lang.Boolean
...
Failed to import HBase Data Model!!!
```

è¿™ä¸ªæ˜¯commons-configuration-{version}çš„ç‰ˆæœ¬å†²çªï¼ŒåŸå…ˆimport hbaseè°ƒç”¨1.6ç‰ˆæœ¬ï¼Œè¿™é‡Œè¦ç”¨1.10ç‰ˆæœ¬ï¼Œæ‰€ä»¥è¦ä¿®æ”¹import-hbase.shçš„è„šæœ¬ã€‚

import-hbase.shä¸­ï¼š

```
CP="/data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/commons-configuration-1.10.jar:${HBASE_CP}:${HADOOP_CP}:${ATLASCPPATH}"
```

ä¿®æ”¹å®Œåï¼Œç»ˆäºèƒ½è¾“å…¥è´¦æˆ·/å¯†ç äº†ï¼Œä½†æ˜¯ä¸‹ä¸€ä¸ªå‘åˆæ¥äº†ï¼š

```
>>>>> hook-bin/import-hbase.sh
>>>>> /data/servers/atlas-2.1.0
Using HBase configuration directory [/data/servers/hbase-2.2.6/conf]
Log file for import is /data/servers/atlas-2.1.0/logs/import-hbase.log
Enter username for atlas  :- admin
Enter password for atlas  :- 
Exception in thread "main" java.lang.NoClassDefFoundError: org/apache/htrace/core/Tracer
...
Caused by: java.lang.ClassNotFoundException: org.apache.htrace.core.Tracer
...
Failed to import HBase Data Model!!!
```

ä¸å°±æ˜¯ç¼ºåŒ…å—ï¼é€šè¿‡findå‘½ä»¤æ‰¾åˆ°å¯èƒ½å…³è”jaråŒ…ï¼Œç„¶åå¼€å§‹åšèµ·æ¬è¿å·¥çš„æœ¬èŒå·¥ä½œï¼š

```
find /data/servers/atlas-2.1.0/ -name htrace-core*
```

æ‰¾åˆ°ä¸¤ä¸ªå«Œç–‘äººï¼š

```
/data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/htrace-core-3.2.0-incubating.jar
/data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/htrace-core4-4.1.0-incubating.jar
```

ç„¶åå˜¿å˜¿ï¼Œéƒ½ç²˜åˆ°$HBASE_HOME/libï¼Œå…¶å®è¯•äº†ä¸€ä¸‹ï¼Œå¥½åƒæ˜¯è°ƒç”¨äº†htrace-core4é‡Œçš„æ–¹æ³•ï¼š

```
cp /data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/htrace-core-3.2.0-incubating.jar $HBASE_HOME/lib
cp /data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/htrace-core4-4.1.0-incubating.jar $HBASE_HOME/lib
```

OK! æˆäº†ï¼å¯åœ¨http://30.23.5.180:21000é¡µé¢æ£€ç´¢hbase_namespaceã€hbase_column_familyã€hbase_tableç­‰æŸ¥çœ‹æˆåŠŸæ¤å…¥çš„æ•°æ®ã€‚

```
>>>>> hook-bin/import-hbase.sh
>>>>> /data/servers/atlas-2.1.0
Using HBase configuration directory [/data/servers/hbase-2.2.6/conf]
Log file for import is /data/servers/atlas-2.1.0/logs/import-hbase.log
Enter username for atlas  :- admin
Enter password for atlas  :- 
HBase Data Model imported successfully!!!
```

#### 1.5 é‡å¯HBaseéªŒè¯HookåŠŸèƒ½

HBase-hookç›¸å½“äºAtlasåœ¨HBaseç»„ä»¶é‚£å„¿é©»æ‰çš„å¤–äº¤å®˜ï¼Œéšæ—¶åé¦ˆHBaseé‡Œè¡¨æ ¼çš„åŠ¨å‘ï¼Œåšåˆ°çŸ¥å·±çŸ¥å½¼ï¼Œæ•°æ®æ²»ç†

```
stop-hbase.sh
jps
```

å¯ä»¥çœ‹åˆ°ä¸»æœºçš„HMasterè¿›ç¨‹è¢«åœç”¨äº†ï¼Œå¿ƒé‡Œé»˜æ•°ä¸‰ä¸ªæ•°ï¼Œç„¶åé‡å¯ï¼š

```
start-hbase.sh
jps
```

æ£€æŸ¥åˆ°HMasterçš„è¿›ç¨‹åˆå‡ºç°äº†ï¼Œè¯´æ˜hookçš„é…ç½®æ²¡æœ‰å½±å“åˆ°HBaseçš„æ­£å¸¸å¯åŠ¨ï¼Œç„¶åéªŒè¯ä¸€ä¸‹hookæœ‰æ²¡æœ‰åšäº‹ï¼Œåœ¨hbaseåˆ›å»ºä¸€ä¸ªtableè¯•è¯•ï¼š

```
hbase shell
hbase(main):001:0> create 'test', 'cf'
hbase(main):001:0> list 'test'
hbase(main):001:0> describe 'test'
hbase(main):001:0> put 'test', 'row1', 'cf:a', 'value1'
hbase(main):001:0> put 'test', 'row2', 'cf:b', 'value2'
hbase(main):001:0> put 'test', 'row3', 'cf:b', 'value3'
hbase(main):001:0> scan 'test'
hbase(main):001:0> get 'test', 'row1'
```

ä»¥ä¸Šåœ¨HBaseå»ºé€ äº†ä¸€ä¸ªä»¥testä¹‹åæœ‰ä¸‰è¡Œæ•°æ®çš„è¡¨æ ¼ï¼Œå…ˆæŸ¥çœ‹ä¸€ä¸‹HBaseé£å›¢ä½¿æœ‰æ²¡æœ‰è¸ä¸Šä¸ç»¸ä¹‹è·¯ï¼š

```
kafka-console-consumer.sh --bootstrap-server 30.23.5.180:9092,30.23.4.69:9092,30.23.5.206:9092 --topic ATLAS_HOOK --from-beginning|jq
```

å¯ä»¥çœ‹åˆ°hbase_namespaceã€hbase_column_familyã€hbase_tableåœ¨è·¯ä¸Šäº†ï¼Œè¿™æ—¶å€™è®¿é—®http://30.23.5.180:21000æ£€ç´¢å®ƒä»¬çš„æ¥è®¿è®°å½•ï¼Œå¯ä»¥çœ‹åˆ°å®ƒä»¬å·²ç»åˆ°äº†è€Œä¸”åœ¨Atlasä¸Šç™»è®°è¿‡äº†ï¼ŒçœŸæ˜¯ä»¤äººæŒ¯å¥‹çš„æ¶ˆæ¯ï¼æœ‰äº†å‰è½¦ä¹‹é‰´ï¼ŒAtlaså¼€å§‹å¤§å¼ æ——é¼“åœ¨Hiveä¹Ÿæ•´ä¸ªè®¿å›¢ã€‚

### 2. æ•´åˆHive

Atlasåœ¨Hiveç»„ä»¶ä¸­ç™»è®°ä¸€ä¸ªé’©å­ç”¨æ¥ç›‘å¬å®ƒçš„create/update/deleteçš„æ“ä½œå¹¶ä¸”é€šè¿‡Kafkaé€šçŸ¥æ¥æ›´æ–°å­˜åœ¨Atlasé‡Œçš„Hiveå…ƒæ•°æ®

#### 2.1 ä¿®æ”¹$HIVE_HOME/confé‡Œçš„hive-site.xmlï¼š

```
vim /data/servers/hive-2.0.1/conf/hive-site.xml
```

åœ¨åŸå…ˆçš„hive-site.xmlæ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ï¼š

```
<property>
    <name>hive.exec.post.hooks</name>
    <value>org.apache.atlas.hive.hook.HiveHook</value>
</property>
```

#### 2.2 ä¿®æ”¹$HIVE_HOME/libé‡Œçš„hive-env.sh

```
vim /data/servers/hive-2.0.1/conf/hive-env.sh
```

åœ¨åŸå…ˆçš„hive-env.shé‡Œæ·»åŠ å¦‚ä¸‹é…ç½®ï¼š

```
export HIVE_AUX_JARS_PATH=/data/servers/atlas-2.1.0/hook/hive
```

#### 2.3 å¤åˆ¶atlas-2.1.0/confä¸­çš„atlas-application.propertiesåˆ°$HIVE_HOME/confä¸­

atlas-application.propertiesä¸­çš„å¦‚ä¸‹å†…å®¹æ˜¯ç”¨æ¥æ§åˆ¶é’©å­çš„çº¿ç¨‹æ± ä»¥åŠKafkaé€šçŸ¥é…ç½®ï¼š

```
atlas.hook.hive.synchronous=false # whether to run the hook synchronously. false recommended to avoid delays in Hive query completion. Default: false
atlas.hook.hive.numRetries=3      # number of retries for notification failure. Default: 3
atlas.hook.hive.queueSize=10000   # queue size for the threadpool. Default: 10000
atlas.cluster.name=primary # clusterName to use in qualifiedName of entities. Default: primary
atlas.kafka.zookeeper.connect=30.23.4.69:2181,30.23.5.206:2181,30.23.5.180:2181/kafka
atlas.kafka.zookeeper.connection.timeout.ms=30000
atlas.kafka.zookeeper.session.timeout.ms=60000
atlas.kafka.zookeeper.sync.time.ms=20
```

#### 2.4 å¯¼å…¥Hiveå…ƒæ•°æ®

```
cd /data/servers/atlas-2.1.0
bin/import-hive.sh
```

é™¤äº†ä¸Šè¿°å…¨å¯¼å…¥ä¹‹å¤–è¿˜å¯ä»¥é€‰æ‹©å¯¼å…¥ç‰¹å®šçš„è¡¨æ ¼æˆ–è€…åœ¨ç‰¹å®šæ•°æ®åº“çš„è¡¨æ ¼ï¼Œç”¨æ³•å¦‚ä¸‹ï¼š

```
Usage 1: <atlas package>/bin/import-hive.sh
Usage 2: <atlas package>/bin/import-hive.sh [-d <database regex> OR --database <database regex>] [-t <table regex> OR --table <table regex>]
Usage 3: <atlas package>/bin/import-hive.sh [-f <filename>]
           File Format:
             database1:tbl1
             database1:tbl2
             database2:tbl1
```

ä¸‹é¢å¼€å§‹è¸©å‘è®°å½•ï¼š

```
...
Caused by: org.apache.commons.configuration.ConversionException: 'atlas.graph.index.search.solr.wait-searcher' doesn't map to a List object: true, a java.lang.Boolean
...
Failed to import Hive Meta Data!!!
```

è¿™ä¸ªæ˜¯commons-configuration-{version}çš„ç‰ˆæœ¬å†²çªï¼ŒåŸå…ˆimport hiveè°ƒç”¨1.6ç‰ˆæœ¬ï¼Œè¿™é‡Œè¦ç”¨1.10ç‰ˆæœ¬ï¼Œæ‰€ä»¥è¦ä¿®æ”¹import-hive.shçš„è„šæœ¬ã€‚

import-hive.shä¸­ï¼š

```
CP="/data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/commons-configuration-1.10.jar:${HIVE_CP}:${HADOOP_CP}:${ATLASCPPATH}"
```

ä¿®æ”¹å®Œè¿™ä¸ªä¹‹åï¼Œç¼ºåŒ…çš„å‘æ¥è¸µè€Œè‡³ï¼Œå…ˆé™ˆåˆ—ä¸€ä¸‹æŠ¥é”™:

Error 1:

```
...
Exception in thread "main" java.lang.NoClassDefFoundError: com/fasterxml/jackson/jaxrs/base/ProvideerBase
...
Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.jaxrs.base.ProviderBase
...
Failed to import Hive Meta Data!!!
```

Error 2:

```
...
Exception in thread "main" java.lang.NoClassDefFoundError: com/fasterxml/jackson/jaxrs/json/JacksonJaxbJsonProvider
...
Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.jaxrs.json.JacksonJaxbJsonProvider
...
Failed to import Hive Meta Data!!!
```

Error 3:

```
...
Exception in thread "main" java.lang.NoClassDefFoundError: com/fasterxml/jackson/module/jaxb/JaxbAnnotationIntrospector
...
Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.module.jaxb.JaxbAnnotationIntrospector
...
Failed to import Hive Meta Data!!!
```

Error 4:

```
...
Exception in thread "main" java.lang.NoClassDefFoundError: com/fasterxml/jackson/core/exc/InputCoercionException
...
Caused by: java.lang.ClassNotFoundException: com.fasterxml.jackson.core.exc.InputCoercionException
...
Failed to import Hive Meta Data!!!
```

å¼€å§‹æ¬è¿å¤§æ³•ï¼š

```
cp /data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/jackson-jaxrs-json-provider-2.9.9.jar hook/hive/atlas-hive-plugin-impl/

cp /data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/jackson-jaxrs-base-2.9.9.jar hook/hive/atlas-hive-plugin-impl/

cp /data/servers/atlas-2.1.0/server/webapp/atlas/WEB-INF/lib/jackson-module-jaxb-annotations-2.9.9.jar hook/hive/atlas-hive-plugin-impl/

cp /data/servers/spark-3.0.1/jars/jackson-core-2.10.0.jar hook/hive/atlas-hive-plugin-impl/
```

ä»¥ä¸Šåˆ†åˆ«è§£å†³ä¸Šè¿°é—®é¢˜ã€‚æœŸé—´è¿˜å‘ç”Ÿä¸€ä¸ªéœ€è¦æ”¹æºç åŒ…é‡Œçš„ä»£ç é‡æ–°å°è£…jaråŒ…çš„é”™è¯¯ï¼š

Error 5ï¼š

```
java.lang.NoSuchMethodError: org.apache.hadoop.hive.metastore.api.Database.getCatalogName()Ljava/lang/String;
```

ä¿®æ”¹æºç åŒ…addons/hive-bridge/src/main/java/org/apache/atlas/hive/bridge/HiveMetaStoreBridge.javaä¸­çš„getDatabaseName()æ–¹æ³•å³å¯ã€‚

ä¿®æ”¹å‰ï¼š

```
public static String getDatabaseName(Database hiveDB) {
    String dbName      = hiveDB.getName().toLowerCase();
    String catalogName = hiveDB.getCatalogName() != null ? hiveDB.getCatalogName().toLowerCase() : null;

    if (StringUtils.isNotEmpty(catalogName) && !StringUtils.equals(catalogName, DEFAULT_METASTORE_CATALOG)) {
        dbName = catalogName + SEP + dbName;
    }

    return dbName;
}
```

æ’æŸ¥åå‘ç°Atlasä»£ç ä¸­ç”¨çš„Hiveç‰ˆæœ¬ä¸º3.1.0ï¼Œè€Œç¯å¢ƒä¸­çš„Hiveæ˜¯2.0.1ã€‚hive-bridgeæ¨¡å—ä¸­è°ƒç”¨äº†2.0.1ç‰ˆæœ¬ä¸­ä¸å­˜åœ¨çš„æ–¹æ³•æŠ¥é”™å¯¼è‡´ã€‚æ³¨é‡Šæ‰éƒ¨åˆ†ä»£åï¼š

```
public static String getDatabaseName(Database hiveDB) {
    String dbName      = hiveDB.getName().toLowerCase();
    /*
    String catalogName = hiveDB.getCatalogName() != null ? hiveDB.getCatalogName().toLowerCase() : null;

    if (StringUtils.isNotEmpty(catalogName) && !StringUtils.equals(catalogName, DEFAULT_METASTORE_CATALOG)) {
        dbName = catalogName + SEP + dbName;
    }
    */

    return dbName;
}
```

ç„¶åé‡æ–°è¿›addons/hive-bridgeç›®å½•ä¸‹æ‰“åŒ…å‡ºhive-bridge-2.1.0.jarï¼Œæ›¿æ¢åŸå…ˆhook/hive/atlas-hive-plugin-implç›®å½•ä¸‹æ–‡ä»¶å³å¯ã€‚æœ€åï¼Œç»ˆäºï¼š

```
[root@SZD-L0430613 atlas-2.1.0]# bin/import-hive.sh
Using Hive configuration directory [/data/servers/hive-2.0.1/conf]
Log file for import is /data/servers/atlas-2.1.0/logs/import-hive.log
...
Enter username for atlas :- admin
Enter password for atlas :- 
Hive Meta Data imported successfully!!!
```
ä¹‹åè¿›å…¥Atlas Webç•Œé¢http://30.23.5.180:21000 å¯ä»¥æŸ¥çœ‹ä¹‹å‰æ¤å…¥çš„Hiveå…ƒæ•°æ®åŠHBaseè¡¨æ ¼ï¼Œåœ¨shellä¹Ÿå¯ä»¥é€šè¿‡curlå‘½ä»¤æŸ¥çœ‹ç›¸å…³ä¿¡æ¯ï¼Œæ¯”å¦‚ï¼š

```
curl http://admin:admin@30.23.5.180:21000/api/atlas/entities?type=hive_db
curl -u admin:admin http://localhost:21000/api/atlas/v2/search/basic?typeName=hive_db
```

è¯¦ç»†APIå¯æŸ¥çœ‹ https://atlas.apache.org/api/v2/index.html

åœ¨shellä¸­æŸ¥çœ‹Atlasé€šè¿‡Kafkaèƒ½æŸ¥çœ‹å…³äºentityåˆ›å»ºçš„é€šä¿¡çš„æ¶ˆè´¹æ•°æ®ï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

```
kafka-console-consumer.sh --bootstrap-server 30.23.5.180:9092 --topic Atlas_ENTITIES --from-beginning|jq
```

#### 2.5 é‡å¯HiveéªŒè¯HookåŠŸèƒ½

```
jps
ps -ef|grep hive
```

å¯ä»¥æŸ¥çœ‹åˆ°JVMçš„ä¸¤ä¸ªRunJarè¿›ç¨‹åˆ†åˆ«æ˜¯Hive serverä»¥åŠHive metastoreçš„æœåŠ¡ï¼Œè·å–å®ƒä»¬çš„pidï¼Œç„¶åé€šè¿‡ç›´æ¥æ‹†ç‚¸å¼¹å‰ªçº¿çš„æ–¹å¼ï¼Œåœæ­¢è¿™ä¸¤ä¸ªè¿›ç¨‹

```
kill -9 <metastore's pid>
kill -9 <hiveserver2's pid>
```

ç„¶åå¿ƒä¸­ç¥ˆç¥·ä¸€åˆ‡é¡ºåˆ©ï¼Œå¼€å§‹é‡å¯ï¼š

```
nohup hive --service metastore >> /data/servers/hive-2.0.1/metastore.log 2>&1 &
nohup hive --service hiveserver2 >> /data/servers/hive-2.0.1/hiveserver2.log 2>&1 &
jps
pe -ef|grep hive
```

ä¸¤ä¸ªè¿›ç¨‹åˆè§é¢äº†ï¼Œè¯´æ˜hive-hookå¤§æ¦‚ç‡å®‰æ’æˆåŠŸäº†ã€‚éªŒè¯ä¸€ä¸‹hookçš„åŠŸèƒ½é€šä¸ï¼š

```
hive
.........
hive> create database atlasdemo;
hive> use atlasdemo;
hive> create table `test` (
hive>   `name` string,
hive>   `age` int
hive> );
hive> insert into `test` values ('xiaozeng', 19);

kafka-console-consumer.sh --bootstrap-server 30.23.5.180:9092,30.23.4.69:9092,30.23.5.206:9092 --topic ATLAS_HOOK --from-beginning|jq
```

æŸ¥çœ‹åˆ°æ¶ˆæ¯é˜Ÿåˆ—æœ‰æ–°å»ºdbçš„æ¶ˆæ¯ï¼Œç„¶åå¯ä»¥è®¿é—®http://30.23.5.180:21000 æ£€ç´¢hive_dbæŸ¥çœ‹åˆ°æ–°å»ºçš„databaseçš„è¯¦æƒ…ï¼Œè¯´æ˜hive-hookçš„åŠŸèƒ½åŸºæœ¬OKï¼

# Apache Atlaså­¦ä¹ ä¹‹è·¯

## ä¸€ã€çœ‹Atlaså¦‚ä½•å±•ç°hiveè¡¨æ ¼äº²ç¼˜å…³ç³»

hiveè¡¨çš„è¡€ç¼˜å…³ç³»å›¾æ˜¯ç”±ä¸€åˆ‡ç”±å®ƒäº§ç”Ÿä»¥åŠä¸€åˆ‡ä¸ºäº†äº§ç”Ÿå®ƒçš„å®ä½“ç»„æˆã€‚

hiveå»ºè¡¨å‚è€ƒï¼šhttps://www.cnblogs.com/qingyunzong/p/8747656.html

### ä¾‹å­1: æ±‚å•æœˆè®¿é—®æ¬¡æ•°å’Œæ€»è®¿é—®æ¬¡æ•°

å‡†å¤‡é€šè¿‡è‡ªå®šä¹‰æ•°æ®ï¼Œå»ºé€ ä¸€å¼ å¤–éƒ¨è¡¨ï¼Œç„¶åé€šè¿‡è¿™å¼ è¡¨è¿›è¡Œæ•°æ®åˆ†æ

/root/zxx_test_data/access.txt

```
A,2015-01,5
A,2015-01,15
B,2015-01,5
A,2015-01,8
B,2015-01,25
A,2015-01,5
A,2015-02,4
A,2015-02,6
B,2015-02,10
B,2015-02,5
A,2015-03,16
A,2015-03,22
B,2015-03,23
B,2015-03,10
B,2015-03,1
```
ä¸Šè¿°è¡¨å­—æ®µåˆ†åˆ«æ˜¯ï¼šç”¨æˆ·åã€æœˆä»½ã€è®¿é—®æ¬¡æ•°; ç„¶åå¼€å§‹å»ºé€ atlasçš„hiveå®ä¾‹ï¼›ä¸ºäº†å®æ—¶æŸ¥çœ‹atlasä¿¡é“æ•°æ®ï¼Œæœ¬äººåœ¨mobaxtermä¸Šå¼€äº†ä¸¤ä¸ªterminalç•Œé¢ï¼Œå…¶ä¸­ä¸€ä¸ªç”¨æ¥æŸ¥çœ‹kafkaçš„æ¶ˆè´¹æ•°æ®ï¼Œå¦å¤–ä¸€ä¸ªå¼€å¯hiveå®¢æˆ·ç«¯äº¤äº’ç•Œé¢ï¼Œåˆ†åˆ«å¦‚ä¸‹ï¼š

```
kafka-console-consumer.sh --bootstrap-server 30.23.5.180:9092,30.23.4.69:9092,30.23.5.206:9092 --topic ATLAS_HOOK --from-beginning|jq
```

å¦å¤–ä¸€ä¸ªç»ˆç«¯åœ¨æ‰“å¼€hiveäº¤äº’ç•Œé¢ä¹‹åï¼Œåˆ†åˆ«è¾“å…¥ï¼š

åˆ›å»ºè¡¨ï¼š

```
create database xiaozeng;
use xiaozeng;

create external table if not exists t_access(
uname string comment 'ç”¨æˆ·å',
umonth string comment 'æœˆä»½',
ucount int comment 'è®¿é—®æ¬¡æ•°'
) comment 'ç”¨æˆ·è®¿é—®è¡¨' 
row format delimited fields terminated by "," 
location "/hive/t_access";
```

å¯¼å…¥æ•°æ®å¹¶éªŒè¯æ•°æ®ï¼š

```
load data local inpath "zxx_test_data/access.txt" into table t_access;

select * from t_access;
```

åœ¨æ¯æ¬¡hiveæ“ä½œæ˜¾ç¤ºOKçš„æ—¶å€™ï¼Œå¯ä»¥çœ‹åˆ°å¦å¤–ä¸€ä¸ªä¿¡é“çªç„¶æ¶Œç°æœ‰å…³åˆ›å»ºæ–°çš„hive_dbã€hive_tableã€hive_columnçš„æ¶ˆæ¯å†…å®¹ï¼Œå¾ˆå¥½ï¼Œçœ‹ç€è½¦æ°´é©¬é¾™ï¼Œå¾ˆå®‰å¿ƒï¼

ç„¶åæ ¹æ®åŸå…ˆçš„è¡¨å¦ç«‹å½“æœˆè®¿é—®æ¬¡æ•°è¡¨tmp_accessï¼š

```
create table tmp_access(
name string,
mon string,
num int
); 

insert into table tmp_access 
select uname,umonth,sum(ucount)
 from t_access t group by t.uname,t.umonth;select * from tmp_access;
```

æ¥ç€åˆ†ææ¯ä¸ªç”¨æˆ·çš„æ¯æœˆæ€»è®¿é—®é‡ã€å†å²æœˆæœ€å¤§è®¿é—®é‡ä»¥åŠæ¯æœˆç´¯è®¡è®¿é—®é‡ï¼Œå¹¶äº§å‡ºä¸€ä¸ªè‡ªè¿æ¥è§†å›¾tmp_viewä»¥åŠä¸€å¼ result_accessçš„è¡¨æ ¼ï¼š

```
create view tmp_view as 
select a.name anme,a.mon amon,a.num anum,b.name bname,b.mon bmon,b.num bnum from tmp_access a join tmp_access b 
on a.name=b.name;

select * from tmp_view;

create table result_access as
select anme,amon,anum,max(bnum) as max_access,sum(bnum) as sum_access 
from tmp_view 
where amon>=bmon 
group by anme,amon,anum;
```

å»ºäº†è¿™ä¸‰å¼ è¡¨æ ¼æˆåŠŸåï¼Œé™¤äº†çœ‹åˆ°kafkaä¿¡é“çš„æµæ°´jsonï¼Œæˆ‘ä»¬è¿™æ—¶å€™è®¿é—®atlas UIç•Œé¢ï¼šhttp://30.23.5.180:21000 å·¦è¾¹ğŸ‘ˆæ£€ç´¢hive_dbç„¶åç‚¹å‡»å³è¾¹ğŸ‘‰å‡ºç°çš„xiaozengè¿™ä¸ªhive_db nameçš„å­—æ®µï¼Œè¿›å…¥å®ƒçš„è¯¦æƒ…é¡µé¢ï¼Œç‚¹å‡»Relationshipsçš„tabï¼Œå¯ä»¥çœ‹åˆ°å‰é¢è¿™ä¸‰å¼ è¡¨çš„åç§°æ˜¾ç¤ºåœ¨keyä¸ºtablesçš„valueä¸‹ï¼Œç„¶åéšæ„ç‚¹å‡»å…¶ä¸­ä¸€å¼ è¡¨ï¼Œæ¯”å¦‚t_accessï¼Œè·³è½¬åˆ°å®ƒçš„è¯¦æƒ…é¡µé¢ï¼Œç‚¹å‡»Lineageçš„tabï¼Œä¸€å¼ å·¨å¹…çš„è¡€ç¼˜ç½‘ç»œå‡ºç°åœ¨ä½ çœ¼å‰ï¼Œä»å·¦åˆ°å³åˆ†åˆ«æ˜¯ï¼š

```
åˆå§‹å¤–éƒ¨è¡¨çš„hdfs_path -> å¯¼å…¥æ•°æ®çš„hive_process -> hive_table t_access -> query t_accessçš„hive_process -> æ ¹æ®queryç»“æœæ–°å»ºçš„hive_table tmp_access -> tmp_accessè‡ªå·±joinè‡ªå·±çš„ hive_process -> è¡¨è§†å›¾hive_table tmp_view -> è”ç«‹ä¸¤å¼ è¡¨çš„å»ºè¡¨è¿‡ç¨‹ hive_process -> æœ€ç»ˆè¾“å‡ºç»“æœhive_table result_access
```

çœ‹åˆ°è¿™é‡Œä¸ç¦å€’å¸ä¸€å£å†·æ°”ï¼Œæ·±æ„Ÿå‡¡äº‹åšè¿‡ï¼Œå¿…ç•™ç—•è¿¹ï¼›ç‚¹å‡»è¿™æ¡å…³ç³»ç½‘ç»œä¸Šçš„å›¾æ ‡å¯ä»¥çœ‹åˆ°è¿™ä¸ªentityçš„å®ä¾‹åŸºæœ¬ä¿¡æ¯çš„å¼¹çª—åŒ…æ‹¬guidã€ç±»å‹ã€åç§°ã€æ‰€æœ‰è€…ã€å»ºç«‹æ—¶é—´ã€çŠ¶æ€ç­‰ï¼Œç‚¹å‡»å›¾æ ‡ä¸Šæ–¹çš„åç§°ï¼Œå¯ä»¥è·³è½¬åˆ°ç›¸åº”å®ä¾‹çš„è¯¦æƒ…é¡µé¢ï¼›æœŸé—´æœ¬äººåˆ é™¤è¿‡å‡ æ¬¡è¡¨ï¼Œåœ¨xiaozengçš„hive_dbè¯¦æƒ…é¡µé¢ä¸ŠRelationshipsçš„tabä¸‹å¯çœ‹åˆ°è¿™äº›tableçš„çŠ¶æ€æ˜¯deletedğŸš®ï¼Œæ—¢ç„¶ä¿¡æ¯è¯¦æƒ…é‚£ä¹ˆè¯¦ç»†ï¼Œé‚£å¦‚æœç»™hiveå»ºç«‹åˆ†åŒºè¡¨ï¼Œé‚£ä¼šæ˜¯æ€ä¹ˆæ ·å‘¢?

### ä¾‹å­2ï¼šå­¦ç”Ÿè¯¾ç¨‹æˆç»©

åœ¨hiveå®¢æˆ·ç«¯ä¸­è¾“å…¥ï¼š

```
createt database partition_test;
use partition_test;

create table course (
id int,
sid int comment 'å­¦å·',
course string comment 'è¯¾ç¨‹',
score int comment 'æˆç»©'
) comment 'å­¦ç”Ÿè¯¾ç¨‹æˆç»©'
partitioned by (dt String, school String)
row format delimited fields terminated by ",";

show tables;
```

å¯ä»¥çœ‹åˆ°å…³äºcourseçš„è¡¨æ ¼å·²ç»å»ºæˆï¼Œkafkaä¿¡é“ä¸Šä¹Ÿæœ‰å‡ºç°å»ºé€ hive_tableçš„å®ä¾‹çš„æ¶ˆæ¯ï¼Œæ¥ï¼Œé€ äº›æ•°æ®:

/root/zxx_test_data/partitions/fudan-1.txt:

```
1,1,Math,89
2,1,CS,76
3,2,Math,99
4,2,CS,99
5,3,Math,100
6,3,CS,100
```

/root/zxx_test_data/partitions/mit-1.txt:

```
1,1,Math,43
2,1,CS,55
3,2,Math,77
4,2,CS,88
5,3,Math,98
6,3,CS,65
```

/root/zxx_test_data/partitions/mit-2.txt:

```
7,4,CS,76
8,4,Math,93
9,5,CS,53
10,5,Math,75
11,6,CS,68
12,6,Math,66
13,7,CS,85
14,7,Math,93
```

ç„¶åæ ¹æ®æ—¶é—´ï¼Œå­¦æ ¡åˆ†åŒºå¯¼å…¥æ•°æ®åˆ°courseè¡¨ä¸­ï¼Œåœ¨hiveå®¢æˆ·ç«¯ä¸­è¾“å…¥ï¼š

```
load data local inpath 'zxx_test_data/partitions/mit-1.txt' into table course partition (dt='2021-01-27',school='MIT');
load data local inpath 'zxx_test_data/partitions/mit-2.txt' into table course partition (dt='2021-01-28',school='MIT');
load data local inpath 'zxx_test_data/partitions/fudan-1.txt' into table course partition (dt='2021-01-26',school='Fudan');
```
åœ¨kafkaä¿¡é“ä¸Šçœ‹åˆ°æ¶ˆæ¯åï¼Œè®¿é—®http://30.23.5.180:21000 å·¦è¾¹ğŸ‘ˆæ£€ç´¢hive_tableï¼Œ`Search By Term`ä¸­è¾“å…¥`course`å¯ä»¥çœ‹åˆ°è¯¦æƒ…é¡µé¢ï¼Œpropertiesä¸‹é¢å‡ºç°partitionKeysçš„å­—æ®µï¼Œé‡Œé¢æœ‰ä¹‹å‰åˆ›çš„åˆ†åŒºå€¼`dt`å’Œ`school`ï¼Œç‚¹å‡»`dt`æŸ¥çœ‹è¯¦æƒ…ï¼Œå‘ç°å®ƒè¢«å½’ç±»ä¸ºhive_columnï¼Œå¥½åƒåˆ†åŒºä¹Ÿå°±ç›¸å½“äºç»™åŸè¡¨åŠ ä¸€ä¸ªcolumnï¼Œç»§ç»­ç»™`course`è¡¨åŠ ä¸€äº›äº²ç¼˜å…³ç³»è¡¨ï¼Œçœ‹çœ‹ä¼šä¸ä¼šäº§ç”Ÿä»€ä¹ˆè£‚å˜ï¼Œæ¯”å¦‚ï¼š

```
create view tmp_course as
select sid, case course when "Math" then score else 0 end as Math,
case course when "CS" then score else 0 end as CS from course;

select * from tmp_course_view;

create view tmp_course_view1 as
select aa.sid, max(aa.Math) as Math, max(aa.CS) as CS from tmp_course_view aa group by sid;

select * from tmp_course_view1;

create table CS_gt_MAth_sid
comment 'è®¡ç®—æœºæˆç»©æ¯”æ•°å­¦å¥½çš„æˆç»©æœ€å¥½çš„å­¦ç”Ÿ' as
select * from tmp_course_view1 where CS > Math;
```

ç„¶åä¸Šatlas UIé¡µé¢æŸ¥çœ‹courseçš„äº²ç¼˜å…³ç³»ï¼Œå‘ç°å®ƒå¹¶æ²¡æœ‰æŠŠcourseè¿™ä¸ªhive_tableå®ä½“æ‹†å¼€ï¼Œçœ‹æ¥atlasåœ¨ç®¡ç†å„ä¸ªç»„ä»¶çš„æ—¶å€™ç»†ç²’åº¦çº§å°±æ˜¯è¿™äº›å®ä½“ï¼Œè€Œpartitionsè¢«å½’ä¸ºhive_column

## äºŒã€Atlasç±»å‹ç³»ç»Ÿä¸Rest API

å‚è€ƒï¼š

http://atlas.apache.org/api/v2/index.html

https://blog.csdn.net/x_iaoa_o/article/details/109581930

https://blog.csdn.net/wangpei1949/article/details/87891862

### 1. Apache Atlasç»„ä»¶å®˜ç½‘ç»¼è¿°

ä¸æ‰åœ¨è¿™é‡Œç¿»è¯‘å¹¶ç®€è¦æ¦‚æ‹¬ä¸€ä¸‹å®˜ç½‘æ‰€ä»‹ç»çš„atlasç»“æ„ï¼ŒåŠ ä¸Šè‡ªå·±çš„ç†è§£ï¼Œå¦‚è‹¥ç†è§£æœ‰æ‰€ä¸å¦¥ï¼Œæ¬¢è¿æŒ‡å‡ºï¼š

#### a. Atlasæ ¸å¿ƒç»„ä»¶`Core`

`ç±»å‹ç³»ç»Ÿï¼ˆType Systemï¼‰`ï¼šå°†æ‰€æœ‰æŠ€æœ¯ç±»çš„å…ƒæ•°æ®`technical metadata`ä»¥åŠä¸šåŠ¡ç±»çš„å…ƒæ•°æ®`business metadata`å¯¹è±¡åŒ–æˆä¸€ä¸ªä¸ªå®ä½“`entity`ï¼Œæ¯ä¸ªå®ä½“åˆ†å±äºä¸€ç§ç±»å‹`type`ï¼Œç„¶åå°†ä»–ä»¬çš„å…³ç³»ç´§å¯†è”ç³»èµ·æ¥ã€‚


```
æŠ€æœ¯ç±»å…ƒæ•°æ®ï¼šæœåŠ¡äºåˆ¶é€ å¯¹è±¡å…ƒæ•°æ®çš„ä¸­é—´äº§ç‰©ï¼Œå¯¹äºç”¨æˆ·æ²¡æœ‰ä»»ä½•å®è´¨å¸®åŠ©
ä¸šåŠ¡ç±»å…ƒæ•°æ®ï¼šå¤§æ•°æ®å¤„ç†å‘ˆç°ç»™ç”¨æˆ·çš„æœ€ç»ˆäº§ç‰©ï¼Œç›´æ¥ç”¨äºæŒ‡å¯¼ç®¡ç†ä¸šåŠ¡ç±»æ•°æ®çš„æ•°æ®

å®ä½“ï¼šç”¨æˆ·å®šä¹‰çš„å…·ä½“çš„æ•°æ®åº“ã€è¡¨æ ¼ã€kafkaè¯é¢˜ç­‰ç­‰
ç±»å‹: å°†atlasæ‰€æœ‰é›†æˆç»„ä»¶å¦‚Hiveã€HBaseå¤§å¸å…«å—ï¼ŒåŒ…æ‹¬æ‰€æœ‰åœ¨Atlas UIé¡µé¢`Search By Type`ä¸‹æ‹‰è¡¨å•çš„æ‰€æœ‰å†…å®¹ã€å¸¸è§çš„æ¯”å¦‚hbase_column_familyã€hbase_namespaceã€hbase_tableã€hdfs_pathã€hive_columnã€hive_dbã€hive_tableã€LoadProcessã€StorageDesc
```

`å›¾åƒå¼•æ“ï¼ˆGraph Engineï¼‰`ï¼šç”¨æ¥ç»™æ¯ä¸ªå®ä½“å»ºç«‹ä¸€ä¸ªä¿¡æ¯æ ‘ğŸŒ²ç»“æ„ï¼Œæ–¹ä¾¿ç”¨æˆ·åŠè‡ªå·±æ£€ç´¢å…ƒæ•°æ®å¯¹è±¡ï¼Œå…·è±¡åŒ–è¡¨ç°ä¸ºäº²ç¼˜å›¾`Lineage`ä»¥åŠæ„é€ å…³ç³»å›¾`Relationships`ã€‚

`å¯¼å…¥ä¸åé¦ˆï¼ˆIngest/Exportï¼‰`ï¼šé€šè¿‡importçš„æ–¹æ³•è°ƒç”¨å¯¼å…¥ç»„ä»¶åŸæœ‰å…ƒæ•°æ®ä»¥åŠé€šè¿‡atlaså®‰æ’åœ¨å„ç»„ä»¶çš„hookåŠkafkaä¿¡é“å®æ—¶åé¦ˆå®ä½“çš„æˆé•¿å˜åŒ–ã€‚

#### b. æ•´åˆéƒ¨åˆ†`Integration`åŒ…æ‹¬`REST API`ä»¥åŠ`ä¿¡ä½¿Messaging`

`REST API`: ç”¨æˆ·å¯ä»¥é€šè¿‡å®ƒåˆ›å»ºã€æ›´æ–°å¹¶ä¸”åˆ é™¤`ç±»å‹`åŠ`å®ä½“`ï¼Œåšåˆ°æŒŸå¤©å­ä»¥ä»¤è¯¸ä¾¯ã€‚ä¸è¿‡æ„Ÿè§‰æ¯”è¾ƒéº»çƒ¦ï¼Œæ¡ä»¶å…è®¸çš„è¯åˆ›å»ºåŠæ›´æ–°çš„å·¥ä½œè¿˜æ˜¯äº¤ç»™å„ä¸ªç»„ä»¶å§ã€‚

`ä¿¡ä½¿Messaging`ï¼šé€šè¿‡atlaså®‰æ’åœ¨å„ä¸ªç»„ä»¶çš„hookç”Ÿäº§æ•°æ®ï¼Œç„¶åé€šè¿‡ATLAS-HOOKä»¥åŠATLAS-ENTITIESä¸¤å¤§kafkaä¿¡é“è·å–æ¶ˆè´¹æ•°æ®ã€‚

#### c. å…ƒæ•°æ®æ¥æº`Metadata sources`

è¿™éƒ¨åˆ†æ˜¯ä¸‡æ¶ä¹‹æºï¼Œä¸è¿‡atlasè¿˜æ˜¯å¾ˆå¼ºå¤§çš„ï¼Œæ”¯æŒå¯¼å…¥ç®¡ç†ä»¥ä¸‹ä½†ä¸é™äºå…ƒæ•°æ®æ¥æºï¼šHBaseã€Hiveã€Sqoopã€Stormã€Kafkaï¼Œå¯¼å…¥æ„å‘³ç€æœ‰åŠŸèƒ½å³æ—¶æˆ–è€…æ‰¹æ¬¡å¤„ç†å…ƒæ•°æ®çš„å¯¼å…¥ï¼Œç®¡ç†æ„å‘³ç€atlasè‡ªå·±æœ¬èº«èƒ½å®šä¹‰è¿™äº›ç»„ä»¶çš„å…ƒæ•°æ®å¯¹è±¡ã€‚

#### d. åº”ç”¨`Applications`

`Atlasç®¡ç†ç”¨æˆ·ç•Œé¢Atlas Admin UI`ï¼šæä¾›ç½‘é¡µåº”ç”¨ç¨‹åºä»¥ä¾›å¤§æ•°æ®ç®¡å®¶ä»¥åŠç§‘å­¦å®¶ç†è§£æ³¨é‡Šå…ƒæ•°æ®ï¼Œä½†æ˜¯ä¸»è¦æ˜¯ç”¨æ¥æ£€ç´¢çš„ç•Œé¢ï¼Œæ”¯æŒä»»ä½•ç±»ä¼¼sqlçš„æ£€ç´¢è¯­å¥ï¼Œç”¨Rest APIæ¥å®ç°å®ƒçš„åŠŸèƒ½ã€‚

`æ ‡ç­¾æ²»ç†Tag Based Policies`ï¼šé€šè¿‡Apache Rangeræ¥æ›´é«˜æ•ˆå®‰å…¨åœ°ç®¡ç†å…ƒæ•°æ®ã€‚

### 2. å¸¸ç”¨Rest API

#### a. AdminREST

æŸ¥çœ‹Atlas Metadata ServerèŠ‚ç‚¹çŠ¶æ€ `GET` /admin/statusï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/admin/status"|jq

ACTIVE:æ­¤å®ä¾‹å¤„äºæ´»è·ƒçŠ¶æ€ï¼Œå¯ä»¥å“åº”ç”¨æˆ·è¯·æ±‚ã€‚
PASSIVE:æ­¤å®ä¾‹å¤„äºè¢«åŠ¨çŠ¶æ€ã€‚å®ƒä¼šå°†æ”¶åˆ°çš„ä»»ä½•ç”¨æˆ·è¯·æ±‚é‡å®šå‘åˆ°å½“å‰ACTIVEå®ä¾‹ã€‚
BECOMING_ACTIVE:æ­¤å®ä¾‹æ­£åœ¨è½¬æ¢ä¸ºACTIVEå®ä¾‹ï¼Œåœ¨æ­¤çŠ¶æ€ä¸‹æ— æ³•ä¸ºç”¨æˆ·æä¾›è¯·æ±‚æœåŠ¡ã€‚
BECOMING_PASSIVE:æ­¤å®ä¾‹æ­£åœ¨è½¬æ¢ä¸ºPASSIVEå®ä¾‹ï¼Œåœ¨æ­¤çŠ¶æ€ä¸‹æ— æ³•ä¸ºç”¨æˆ·æä¾›è¯·æ±‚æœåŠ¡ã€‚

æ³¨æ„ï¼šæ­£å¸¸æƒ…å†µä¸‹ï¼Œåªæœ‰ä¸€ä¸ªåº”è¯¥ä¸ºACTIVEçŠ¶æ€ï¼Œå…¶ä»–å®ä¾‹å‡ä¸ºPASSIVEçŠ¶æ€ã€‚
```

æŸ¥çœ‹Atlasç‰ˆæœ¬å’Œæè¿° `GET` /admin/versionï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/admin/version"|jq
```

#### b. DiscoveryREST

åŸºæœ¬æœç´¢ `GET` /v2/search/basicï¼š

```
#æŸ¥è¯¢æ‰€æœ‰Hiveè¡¨
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/search/basic?typeName=hive_table"|jq

#æŸ¥è¯¢æ‰€æœ‰Hiveè¡¨ï¼Œä¸”åŒ…å«æŸä¸€å…³é”®å­—
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/search/basic?query=custo*&typeName=hive_table"|jq
```

DSL æœç´¢ `GET` /v2/search/dslï¼š

```
#DSLæ–¹å¼æŸ¥è¯¢Hiveè¡¨
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/search/dsl?typeName=hive_table&query=where%20name%3D%22customer%22"|jq

æ³¨æ„:URLä¸­ç‰¹æ®Šå­—ç¬¦ç¼–ç ã€‚
```

å…¨æ–‡æ£€ç´¢ `GET` /v2/search/fulltextï¼š

```
#å…¨æ–‡æ£€ç´¢æ–¹å¼æŸ¥è¯¢
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/search/fulltext?query=where%20name%3D%22customer%22"|jq
```

#### c. TypesREST

æ£€ç´¢æ‰€æœ‰Typeï¼Œå¹¶è¿”å›æ‰€æœ‰ä¿¡æ¯ `GET` /v2/types/typedefsï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/types/typedefs"|jq
```

æ£€ç´¢æ‰€æœ‰Typeï¼Œå¹¶è¿”å›æœ€å°‘ä¿¡æ¯ `GET` /v2/types/typedefs/headersï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/types/typedefs/headers"|jq
å¦‚:
{
    "guid": "77edd2dc-cc4e-4980-ae65-b3dd72cf5980",
    "name": "dim_table",
    "category": "CLASSIFICATION"
  },
  {
    "guid": "9d6c9b56-b91b-45f5-9320-d10c67736d05",
    "name": "fact_table",
    "category": "CLASSIFICATION"
  }
.......
```

#### d. EntityREST

æ‰¹é‡æ ¹æ®GUIDæ£€ç´¢Entity `GET` /v2/entity/bulkï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/entity/bulk?minExtInfo=yes&guid=7a625477-060d-4629-8804-be241271c026"|jq
```

è·å–æŸä¸ªEntityå®šä¹‰ `GET` /v2/entity/guid/{guid}ï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/entity/guid/7a625477-060d-4629-8804-be241271c026"|jq
```

è·å–æŸä¸ªEntityçš„TAGåˆ—è¡¨ `GET` /v2/entity/guid/{guid}/classificationsï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/entity/guid/3b0ceec1-d41d-497a-b63e-d210b9862eef/classifications"|jq
```

#### e. LineageREST

æŸ¥è¯¢æŸä¸ªEntityçš„Lineage GET /v2/lineage/{guid}ï¼š

```
curl -s -u admin:admin "http://30.23.5.180:21000/api/atlas/v2/lineage/c8f071e1-36d7-4a93-bc8f-35b0fa3b113c"|jq
```